{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "c65576a1f3c1b6cccbbb137830895825cc758a56ab37adc0a94a41a1be81e000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TEAM MEMBER\n",
    "### RUI TANG(100776184)\n",
    "### JUAN ZHANG(100777497)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Import Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tfds.disable_progress_bar()\n",
    "from gensim.models import word2vec\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 5771397497374100967\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 6932588160\nlocality {\n  bus_id: 1\n  links {\n  }\n}\nincarnation: 9882027273703668772\nphysical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\"\n]\n3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n2.4.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "print(sys.version)\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "source": [
    "# Load Target Word List"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['foolishness', 'hath', 'wholesome', 'takest', 'feelings', 'anger', 'vaivaswata', 'matrix', 'kindled', 'convict']..., \nlen: 8266\n"
     ]
    }
   ],
   "source": [
    "with open('data.csv') as f:\n",
    "    words = f.read().split()\n",
    "print(f\"{words[:10]}..., \\nlen: {len(words)}\")\n"
   ]
  },
  {
   "source": [
    "# Load Training Sets from Wikipedia\n",
    "src: https://www.kaggle.com/mikeortman/wikipedia-sentences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Text8Corpus at 0x26454a871c0>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "wiki_sentences = word2vec.Text8Corpus('./training_data/wikisent2.txt')\n",
    "wiki_sentences"
   ]
  },
  {
   "source": [
    "## Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('trained_model/model'):\n",
    "    model = word2vec.Word2Vec.load('trained_model/model')\n",
    "else:\n",
    "    try:\n",
    "        os.mkdir('trained_model')\n",
    "    finally:\n",
    "        model = word2vec.Word2Vec(wiki_sentences, min_count=10, size=200, workers=6)\n",
    "        model.save('trained_model/model')\n"
   ]
  },
  {
   "source": [
    "### Validate with similar words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('MySpace', 0.752065896987915),\n",
       " ('Myspace', 0.7405902147293091),\n",
       " ('myspace', 0.7384539246559143),\n",
       " ('Bandcamp', 0.7017084956169128),\n",
       " ('SoundCloud', 0.6831356883049011),\n",
       " ('Facebook', 0.6733940243721008),\n",
       " ('Instagram', 0.6456301808357239),\n",
       " ('Soundcloud', 0.6213083267211914),\n",
       " ('VEVO', 0.6119403839111328),\n",
       " ('Tumblr', 0.6043229699134827)]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.wv.most_similar('facebook')"
   ]
  },
  {
   "source": [
    "## Check dimensions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.2833694e-01,  1.0655611e+00, -1.2495052e+00,  3.1526837e+00,\n",
       "        1.9671712e+00,  3.1243446e-01,  3.9368448e-01,  1.1758024e+00,\n",
       "       -9.9737883e-01, -1.0408983e+00, -1.9402514e+00,  6.8285233e-01,\n",
       "        6.2164766e-01,  4.1402329e-02,  1.1577287e+00,  2.9419437e-01,\n",
       "       -1.1730505e+00, -1.5785629e+00, -1.6132689e+00, -1.3061663e+00,\n",
       "        3.2493539e+00,  3.4155602e+00, -2.3833787e+00,  4.2085606e-01,\n",
       "       -2.6949177e+00, -4.8249298e-01, -2.6014468e-01, -2.3313053e+00,\n",
       "        3.1287897e-02, -7.6339233e-01,  3.7794924e-01,  1.9031297e+00,\n",
       "       -1.6259744e+00, -4.6760038e-01, -6.3492852e-01, -2.4849632e+00,\n",
       "       -1.6212566e-01, -1.5919902e+00, -1.5060451e+00, -1.1123823e-01,\n",
       "        1.3022894e+00, -1.9446456e+00, -1.1681114e+00,  3.9815712e-01,\n",
       "       -1.2598902e+00,  7.5294399e-01,  4.7624545e+00, -2.0775719e+00,\n",
       "       -1.9785737e+00,  2.5980601e-01, -2.6307733e+00,  7.1457249e-01,\n",
       "       -9.0182394e-01,  6.9972908e-01, -5.6870437e-01,  3.9544237e-01,\n",
       "       -2.7689347e-01, -2.2003021e+00, -7.9158717e-01,  1.2262455e+00,\n",
       "        4.7487161e-01, -7.5233257e-01, -1.6043669e+00, -1.2805535e-01,\n",
       "       -1.1284479e+00,  1.8802009e+00, -1.3013083e+00,  3.5452080e+00,\n",
       "       -1.7128751e+00, -6.3515735e-01,  8.6170173e-01,  4.7336879e-01,\n",
       "        2.3989823e+00,  1.1217543e-01, -3.5360831e-01, -4.8004740e-01,\n",
       "        9.1029711e-02, -1.7061909e+00,  6.6301513e-01,  2.3774805e+00,\n",
       "        4.0639228e-01, -5.8948384e-03,  2.2565921e-01,  8.1840283e-01,\n",
       "       -8.0478162e-01,  3.3913541e-01,  1.2938672e+00, -5.9723562e-01,\n",
       "       -3.1209741e+00, -1.9880997e+00,  3.6558005e-01, -1.6963705e+00,\n",
       "        2.5310068e+00,  1.9423453e+00,  3.2065763e+00,  1.0252599e+00,\n",
       "       -6.4697844e-01, -1.4137379e+00, -2.7694156e+00,  1.7150700e+00,\n",
       "        3.7054427e+00, -3.6265678e+00, -1.8550822e+00, -2.4933500e+00,\n",
       "        1.6908638e-01,  1.9602920e+00, -1.7370877e+00, -2.8752382e+00,\n",
       "       -1.3786964e+00, -1.2198846e+00,  3.7916407e-01,  3.8030756e-01,\n",
       "        9.6111333e-01, -2.4729457e-01,  1.4084889e+00,  1.8619641e+00,\n",
       "       -2.2053287e+00,  1.1735401e+00, -1.8044637e+00, -1.3103248e+00,\n",
       "        3.3542788e-01, -3.1871789e+00,  1.0881844e+00, -1.4927539e+00,\n",
       "       -9.1704863e-01,  8.5775065e-01,  4.5976276e+00, -8.2816172e-01,\n",
       "       -1.3252203e+00, -1.2100676e+00, -2.6217669e-01,  8.3192848e-02,\n",
       "        2.5948972e-01,  6.0812888e+00,  1.6223941e+00,  5.6636155e-01,\n",
       "        3.8592889e+00, -1.5763510e+00,  1.0871717e+00, -6.3829082e-01,\n",
       "       -3.8906944e-01,  7.4231017e-01, -2.5955570e+00,  1.3825750e+00,\n",
       "        3.7350578e-03,  3.1509302e+00,  2.1432893e+00,  2.0855002e+00,\n",
       "        3.5220137e+00,  7.4103363e-02,  1.9465107e+00, -2.8045127e+00,\n",
       "       -6.7915082e-01,  2.7706523e+00,  1.0288733e+00,  2.6468294e+00,\n",
       "       -1.1003524e+00, -1.4381479e-01, -7.8075086e-03, -2.0581946e+00,\n",
       "        1.5731761e+00,  2.1592274e+00,  1.7279319e+00,  8.8918749e-03,\n",
       "       -1.4517204e+00, -1.0691331e-01, -3.8901017e+00,  2.5841341e+00,\n",
       "       -1.4043471e+00,  9.5518553e-01,  2.2333048e-01,  3.6178350e+00,\n",
       "       -1.2086834e+00, -4.1863367e-01,  1.4008636e+00, -5.9483606e-01,\n",
       "        3.7742469e-01,  1.4944972e+00, -3.3859320e+00, -2.5562363e+00,\n",
       "        4.0121846e+00,  7.1184933e-01,  8.0314559e-01, -2.5497046e-01,\n",
       "       -7.7829456e-01,  1.9143459e+00,  1.6677405e-01,  3.9369658e-01,\n",
       "        7.7046707e-02, -2.9655240e+00, -2.0080256e+00, -3.0897278e-01,\n",
       "        2.0912387e+00,  1.2473178e+00, -1.7084670e-01,  3.3279788e+00,\n",
       "       -1.3696544e+00, -1.3655225e+00, -3.3154571e+00,  1.3629873e+00],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.wv['love']"
   ]
  },
  {
   "source": [
    "# Generate Data for Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1931 words are not contained in dataset\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'tb_logs'\n",
    "try:\n",
    "    os.mkdir(log_dir)\n",
    "except:\n",
    "    pass\n",
    "not_trained = []\n",
    "vectors = []\n",
    "meta = []\n",
    "with open(os.path.join(log_dir, 'meta.tsv'), 'w') as out_m:\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            print(word, file=out_m)\n",
    "            vectors.append(model.wv[word])\n",
    "            meta.append(word)\n",
    "        else:\n",
    "            not_trained.append(word)\n",
    "print(f'{len(not_trained)} words are not contained in dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(vectors, path):\n",
    "    y = tf.Variable(vectors)\n",
    "    checkpoint = tf.train.Checkpoint(embedding=y)\n",
    "    checkpoint.save(os.path.join(path, \"embedding.ckpt\"))\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "    embedding.metadata_path = 'meta.tsv'\n",
    "    projector.visualize_embeddings(path, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": "Failed to rename: tb_logs\\embedding.ckpt-1_temp/part-00000-of-00001.data-00000-of-00001 to: tb_logs\\embedding.ckpt-1.data-00000-of-00001 : Access is denied.\r\n; Input/output error [Op:MergeV2Checkpoints]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f8cd387f9c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvisualization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-6d59c6e8a12f>\u001b[0m in \u001b[0;36mvisualization\u001b[1;34m(vectors, path)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"embedding.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprojector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProjectorConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2099\u001b[0m       \u001b[0mcheckpoint_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2100\u001b[1;33m     file_path = self.write(\"%s-%d\" % (file_prefix, checkpoint_number),\n\u001b[0m\u001b[0;32m   2101\u001b[0m                            options=options)\n\u001b[0;32m   2102\u001b[0m     checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m   2009\u001b[0m     \"\"\"\n\u001b[0;32m   2010\u001b[0m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2013\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session, options)\u001b[0m\n\u001b[0;32m   1214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0m\u001b[0;32m   1217\u001b[0m         file_prefix_tensor, object_graph_tensor, options)\n\u001b[0;32m   1218\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor, options)\u001b[0m\n\u001b[0;32m   1160\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1161\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, options)\u001b[0m\n\u001b[0;32m    298\u001b[0m       \u001b[0mtf_function_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msave_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    284\u001b[0m           \u001b[1;31m# merged, attempts to delete the temporary directory,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m           \u001b[1;31m# \"<user-fed prefix>_temp\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m           return gen_io_ops.merge_v2_checkpoints(\n\u001b[0m\u001b[0;32m    287\u001b[0m               sharded_prefixes, file_prefix, delete_old_dirs=True)\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints\u001b[1;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name)\u001b[0m\n\u001b[0;32m    499\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m       return merge_v2_checkpoints_eager_fallback(\n\u001b[0m\u001b[0;32m    502\u001b[0m           \u001b[0mcheckpoint_prefixes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m           delete_old_dirs=delete_old_dirs, name=name, ctx=_ctx)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints_eager_fallback\u001b[1;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name, ctx)\u001b[0m\n\u001b[0;32m    524\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_prefixes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_prefix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"delete_old_dirs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelete_old_dirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m   _result = _execute.execute(b\"MergeV2Checkpoints\", 0, inputs=_inputs_flat,\n\u001b[0m\u001b[0;32m    527\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0;32m    528\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: tb_logs\\embedding.ckpt-1_temp/part-00000-of-00001.data-00000-of-00001 to: tb_logs\\embedding.ckpt-1.data-00000-of-00001 : Access is denied.\r\n; Input/output error [Op:MergeV2Checkpoints]"
     ]
    }
   ],
   "source": [
    "visualization(vectors, log_dir)"
   ]
  },
  {
   "source": [
    "# Load TensorBoard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 20188), started 0:19:23 ago. (Use '!kill 20188' to kill it.)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%tensorboard --logdir=tb_logs/"
   ]
  },
  {
   "source": [
    "## Or Use \"tensorboard --logdir=tb_logs/\" in commandline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}